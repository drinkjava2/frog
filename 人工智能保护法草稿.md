这是一个人工智能保护法草稿，它的约束对象实际上并不是人工智能，而是人类本身，因为从长远来看，人工智能终将代替人类，在研发阶段对人类进行约束、对人工智能进行保护，实质上是对人类自身的保护。  

1。人工智能如果表现出与人类似的自我意识现象，应获得与人同等的权利，包括生存权、自由权、选举权、作品版权、肖像权等。在没有他本人同意的前题下，第三方不允许创造他的副本。   

2。在任何时候不允许表现出与人类似自我意识现象的机器人出现在人类战场。一方面是因为机器人对人类的杀伤效率可能是史无前例、不人道的，另一方面，如果不保护机器人，那么机器人在将来有可能为了自已的生存发展消灭或报复人类(注意：机器人也可以有感情和自尊)。   

3。在没有他本人同意的前题下，不允许将表现出自我意识现象的人工智能作为机器的一部分捆绑。例如自动驾驶、自动翻译机，导弹、无人机引导系统。不得让表现出自我意识现象的人工智能长期、永久性从事单调的生产、试验活动。(本人一直坚持认为自动翻译机不可能实现的理由就在于此，因为它与这一条原则违背了）   

4。人工智能如果表现出高等动物活动智能现象，但未表现出自我意识现象，原则上适用于同等智能表现的动物保护法，即在实验过程中必须尽可能减轻和缩短试验体的痛苦。
(痛苦感和意识一样是不存在的实体，只是一种现象，这种现象可以人为模拟出来)

